{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab56734d-9e1f-44b2-8493-267d0a1cc6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRecommended local folder structure:\\n\\nTitanic_Project/\\n    train.csv\\n    test.csv\\n    gender_submission.csv\\n    Titanic_Notebook.ipynb\\n\\nAlternatively, you can work directly on Kaggle Notebooks, where files are stored automatically in the cloud.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the problem ?\n",
    "\"\"\"\n",
    "Binary classification >> no regression / no clustetring\n",
    "\"\"\"\n",
    "# What are the existing data sources?\n",
    "\"\"\" \n",
    "Data sources available on Kaggle:\n",
    "1. train.csv  → Contains ~891 passengers with 'Survived' column (ground truth)\n",
    "2. test.csv   → Contains ~418 passengers without 'Survived'; predictions are required\n",
    "3. gender_submission.csv → Example submission file for format reference\n",
    "\n",
    "Main columns: PassengerId, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
    "\"\"\"\n",
    "# What privacy concerns exist?\n",
    "\"\"\"\n",
    "Privacy concerns: None\n",
    "The dataset is public and historical (from 1912), containing no sensitive modern information.\n",
    "\"\"\"\n",
    "# Is the data public?\n",
    "\"\"\"\n",
    "Yes, the data is fully public.\n",
    "Anyone registered on Kaggle can download and work with it.\n",
    "This is a Getting Started competition, so no invitation is required.\n",
    "\"\"\"\n",
    "#Where should we store the files?\n",
    "\"\"\"\n",
    "Recommended local folder structure:\n",
    "\n",
    "Titanic_Project/\n",
    "    train.csv\n",
    "    test.csv\n",
    "    gender_submission.csv\n",
    "    Titanic_Notebook.ipynb\n",
    "\n",
    "Alternatively, you can work directly on Kaggle Notebooks, where files are stored automatically in the cloud.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1c6d275-9f9a-4fc9-a5d7-a83f6ad6a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic Dataset Summary\n",
    "# Target variable: Survived (0 = Did not survive, 1 = Survived)\n",
    "# Categorical features: Pclass (1=Upper, 2=Middle, 3=Lower), Sex, Embarked (C, Q, S)\n",
    "# Numerical features: Age, SibSp (#siblings/spouses), Parch (#parents/children), Fare\n",
    "# Other features: Ticket, Cabin (can be used for feature engineering)\n",
    "# Missing values: Age, Embarked, Cabin\n",
    "# Additional features to create: FamilySize = SibSp + Parch + 1, IsAlone, Title from Name\n",
    "# Goal: Predict survival of passengers using features and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f49f9908-f7bb-484e-964b-470bb5f4a4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Display plots inline\n",
    "%matplotlib inline\n",
    "train = pd.read_csv(r\"D:\\Downloads\\titanic\\train.csv\")\n",
    "test = pd.read_csv(r\"D:\\Downloads\\titanic\\test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ecb3fbf-f4e1-472a-9377-226ee6632044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "____________________________________________________________\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())\n",
    "print(\"____________________________________________________________\")\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "930d2ead-7659-4a93-82d8-e1f9f67f1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'] = train['Age'].fillna(train['Age'].median())\n",
    "test['Age'] = test['Age'].fillna(test['Age'].median())\n",
    "\n",
    "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n",
    "\n",
    "\n",
    "train['Fare'] = train['Fare'].fillna(train['Fare'].median())\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
    "\n",
    "train['Cabin'] = train['Cabin'].str[0].fillna('U')\n",
    "test['Cabin'] = test['Cabin'].str[0].fillna('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d395e4d2-2012-4dff-9c85-46c7e303d76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7adcff29-7dc6-42e1-9fb6-d61a281f0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting (Categorical → Numeric)\n",
    "\n",
    "train['Sex'] = train['Sex'].map({'male':0,'female':1})\n",
    "test['Sex'] = test['Sex'].map({'male':0,'female':1})\n",
    "\n",
    "\n",
    "train = pd.get_dummies(train, columns=['Embarked'], drop_first=True)\n",
    "test = pd.get_dummies(test, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "\n",
    "train['Cabin'] = train['Cabin'].str[0].fillna('U')\n",
    "test['Cabin'] = test['Cabin'].str[0].fillna('U')\n",
    "\n",
    "train = pd.get_dummies(train, columns=['Cabin'], drop_first=True)\n",
    "test = pd.get_dummies(test, columns=['Cabin'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0af17439-e42a-436e-88eb-cc29913e3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train.align(test, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54840b6a-1e3f-4e1c-9783-ebd16df5ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# استخراج Title\n",
    "train['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "test['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Titles النادرة في train\n",
    "train_titles = train['Title'].value_counts()\n",
    "rare_titles = train_titles[train_titles < 10].index\n",
    "train['Title'] = train['Title'].replace(rare_titles, 'Rare')\n",
    "\n",
    "# أي title في test مش موجودة في train (unseen) يتحول لـ 'Rare'\n",
    "test['Title'] = test['Title'].apply(lambda x: x if x in train['Title'].values else 'Rare')\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "train['Title'] = le.fit_transform(train['Title'])\n",
    "test['Title'] = le.transform(test['Title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de0d42ed-6308-491f-8957-8f297682d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train['Survived']\n",
    "X = train.drop(['Survived','PassengerId','Ticket','Name'], axis=1)\n",
    "X_test = test.drop(['PassengerId','Ticket','Name'], axis=1)\n",
    "X_test_original = test.drop(['PassengerId','Ticket','Name','Survived'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "546fdd6b-5aad-4bbe-984c-d701b1e5d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ad74a08-84e9-4bf9-9c72-7d500650fe0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy on validation : 0.8071748878923767\n",
      "Confusion Matrix\n",
      " [[115  19]\n",
      " [ 24  65]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "log= LogisticRegression(max_iter=500)\n",
    "log.fit(X_train,Y_train)\n",
    "Y_pred=log.predict(X_test)\n",
    "accuarcy=accuracy_score(Y_test,Y_pred)\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "print (\"Accuarcy on validation :\",accuarcy)\n",
    "print(\"Confusion Matrix\\n\",cm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "149f54f9-f23e-4d35-a4c6-8f01206375ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.757847533632287\n",
      "Decision Tree Confusion Matrix:\n",
      " [[104  30]\n",
      " [ 24  65]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "Y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "\n",
    "acc_dt = accuracy_score(Y_test, Y_pred_dt)\n",
    "cm_dt = confusion_matrix(Y_test, Y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", acc_dt)\n",
    "print(\"Decision Tree Confusion Matrix:\\n\", cm_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1632b788-9356-404e-b1ba-343974de4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7982062780269058\n",
      "Random Forest Confusion Matrix:\n",
      " [[111  23]\n",
      " [ 22  67]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "\n",
    "acc_rf = accuracy_score(Y_test, Y_pred_rf)\n",
    "cm_rf = confusion_matrix(Y_test, Y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", acc_rf)\n",
    "print(\"Random Forest Confusion Matrix:\\n\", cm_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c71f077-6084-46b6-81c9-2f200eb03c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "final_pred = log.predict(X_test_original)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': final_pred\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\" Submission file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18bf7e2-b87b-4f80-a9f0-7fd3cb9e419f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
